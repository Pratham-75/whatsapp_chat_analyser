# -*- coding: utf-8 -*-
"""FinalWhatsappChatAnalyzer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VI24M4dRYBx7zFy0wCsLOEnOOTfefF6y
"""

import re
import pandas as pd

chatFile = open("/content/WhatsApp Chat with PE 417 Materials management(E10).txt",'r',encoding='utf-8')

chatsData = chatFile.read()

print(chatsData)

print(type(chatsData))

chatPattern = r'\d{1,2}/\d{1,2}/\d{2,4},\s\d{1,2}:\d{2}\s-\s'

chatMessages = re.split(chatPattern, chatsData)[1:]
len(chatMessages)

chatMessages

print(type(chatsData))

if not isinstance(chatFile, str):
    chatFile = str(chatFile)

chatFile

chatDates = re.findall(chatPattern, chatsData)
chatDates

chatsDataFile = pd.DataFrame({'userMessage':chatMessages, 'messageDate':chatDates})
chatsDataFile['messageDate'] = pd.to_datetime(chatsDataFile['messageDate'], format='%d/%m/%y, %H:%M - ')
chatsDataFile.head(10)

chatsDataFile.shape

usersId = []
currMessages = []
for message in chatsDataFile['userMessage']:
    messageData = re.split('([\w\W]+?):\s', message)
    if messageData[1:]:
      usersId.append(messageData[1])
      currMessages.append(messageData[2])
    else:
      usersId.append('whatsappNotification')
      currMessages.append(messageData[0])

chatsDataFile['userId'] = usersId
chatsDataFile.drop(columns = ['userMessage'], inplace = True)
chatsDataFile['userMessage'] = currMessages
chatsDataFile.head()

chatsDataFile['date'] = chatsDataFile['messageDate'].dt.day
chatsDataFile.head(100)

chatsDataFile['month'] = chatsDataFile['messageDate'].dt.month_name()

chatsDataFile['year'] = chatsDataFile['messageDate'].dt.year

chatsDataFile['hour'] = chatsDataFile['messageDate'].dt.hour

chatsDataFile['minute'] = chatsDataFile['messageDate'].dt.minute

chatsDataFile.head()

"""Messages sent by the user

"""

chatsDataFile['messageDate'] = pd.to_datetime(chatsDataFile['messageDate'])

UserId = input("Enter the userId you want to analyze: ")

UserMessages = chatsDataFile[chatsDataFile['userId'] == UserId]

grouped_data = UserMessages.groupby(UserMessages['messageDate'].dt.date)['userMessage'].agg(list).reset_index()

print(f"Messages for User {UserId} day by day:")
for row in grouped_data.itertuples(index=False):
    day, messages = row
    print(f"Date: {day}")
    print("Messages:")
    for message in messages:
        print(f" - {message}")
    print("----")

chatsDataFile['userId'].unique()

"""Total messages sent in the group by individual or overall"""

def totalMessages(messageRequest):
    if messageRequest == "allUsers":
      return chatsDataFile.shape[0]
    else:
      return chatsDataFile[chatsDataFile['userId'] == messageRequest].shape[0]

totalMessages("Pratham")

"""Total words used by the users"""

totalWords = []
for word in chatsDataFile['userMessage']:
    totalWords.extend(word.split())

len(totalWords)

"""Shared Media by the users"""

chatsDataFile[chatsDataFile['userMessage'] == '<Media omitted>\n'].shape[0]

OmittedMedia = chatsDataFile[chatsDataFile['userMessage'].str.contains('<Media omitted>')]

for UserId, MessageDate in OmittedMedia.groupby('userId')['messageDate']:
    mediaCount = 0
    print(f"User: {UserId}")
    print("Message Dates:")
    for date in MessageDate:
        print(f" - {date}")
        mediaCount = mediaCount+1
    print(f"Total Media Omitted by the {UserId} : {mediaCount}")
    print("\n----")

"""Links or URLs sent by the users"""

!pip install urlextract

from urlextract import URLExtract
urlExtractor = URLExtract()

urls = []
for msg in chatsDataFile['userMessage']:
    urls.extend(urlExtractor.find_urls(msg))

len(urls)

urls

"""Most Busy Users in the group"""

busyUsers = chatsDataFile['userId'].value_counts().head(10)

print(busyUsers)

import matplotlib.pyplot as plt

busyUserName = busyUsers.index
busyUserMessageCount = busyUsers.values

plt.bar(busyUserName, busyUserMessageCount)
plt.xticks(rotation='vertical')
plt.show()

round((chatsDataFile['userId'].value_counts()/chatsDataFile.shape[0])*100,2).reset_index().rename(columns={'userId':'userName', 'count':'percent'}).head(20)

"""Messages deleted by the users"""

chatsDataFile['messageDate'] = pd.to_datetime(chatsDataFile['messageDate'])

MessagesDeleted = chatsDataFile[chatsDataFile['userMessage'].str.contains("This message was deleted", case=False, na=False)]

if not MessagesDeleted.empty:
    CountOfMessages = MessagesDeleted['userId'].value_counts()
    DifferentUserId = MessagesDeleted['userId'].unique()

    print("Frequency of the messages:")
    print(CountOfMessages)

    print("\Different UserIds:")
    print(DifferentUserId)
else:
    print("Not Found 'This message was deleted'")

"""emojis used by users"""

def extract_emojis(text):
    PatternOfEmojis = re.compile("["
                               u"\U0001F600-\U0001F64F"
                               u"\U0001F300-\U0001F5FF"
                               u"\U0001F680-\U0001F6FF"
                               u"\U0001F700-\U0001F77F"
                               u"\U0001F780-\U0001F7FF"
                               u"\U0001F800-\U0001F8FF"
                               u"\U0001F900-\U0001F9FF"
                               u"\U0001FA00-\U0001FA6F"
                               u"\U0001FA70-\U0001FAFF"
                               u"\U00002702-\U000027B0"
                               u"\U000024C2-\U0001F251"
                               "]+", flags=re.UNICODE)
    return PatternOfEmojis.findall(text)

chatsDataFile['emojisUsed'] = chatsDataFile['userMessage'].apply(extract_emojis)

for userId, emojisUsed in chatsDataFile.groupby('userId')['emojisUsed']:
    emojisList = [emoji for emojis in emojisUsed for emoji in emojis]

    if len(emojisList):
      print(f"User: {userId}")
      print(f"Emojis Used: {emojisList}")
      print("\n----")

"""based on emoji their positive and negative and neutral expressions"""

!pip install emoji

from collections import Counter

import emoji

"""Emojis send by an individual and sentiment analysis based on emojis"""

def sentimentAnalysis(emojis):
    positive_emojis = [':)', 'ðŸ˜Š', 'ðŸ˜„', 'ðŸ‘', 'â¤', 'ðŸ˜ƒ', 'ðŸ˜', 'ðŸ¤£']
    negative_emojis = [':(', 'ðŸ˜”', 'ðŸ˜¢', 'ðŸ‘Ž', 'ðŸ˜ž', 'ðŸ˜ ']

    positiveCount = sum(emoji in positive_emojis for emoji in emojis)
    negativeCount = sum(emoji in negative_emojis for emoji in emojis)

    if positiveCount > negativeCount:
        sentiment = 'Positive'
    elif negativeCount > positiveCount:
        sentiment = 'Negative'
    else:
        sentiment = 'Neutral'

    return sentiment

def UserSentimentAnalysis(chatsDataFile, UserId):
    userMessages = chatsDataFile[chatsDataFile['userId'] == UserId]

    userMessages['emojisUsed'] = userMessages['userMessage'].apply(extract_emojis)

    emojisList = [emoji for emojis in userMessages['emojisUsed'] for emoji in emojis]

    sentiment = sentimentAnalysis(emojisList)

    return emojisList, sentiment

UserId = input("Enter the userId you want to Analyse: ")

emojisUsedByTheUser, sentimentOfTheUser = UserSentimentAnalysis(chatsDataFile, UserId)

print(f"Emojis used by the User {UserId}: {emojisUsedByTheUser}")
print(f"Sentiment analysis for the User {UserId}: {sentimentOfTheUser}")
print("\n\n\n")

chatsDataFile.head()

"""Most Used Words in the group"""

import collections
import matplotlib.pyplot as plt
from collections import Counter

words = []
for message in chatsDataFile['userMessage']:
    words.extend(re.findall(r'\b[A-Za-z]+\b', message))

word_counts = Counter(words)

most_used_words = word_counts.most_common(10)

print("Top 10 most used words:")
for word, count in most_used_words:
    print(f"{word}: {count}")

plt.bar(range(10), [count for word, count in most_used_words])
plt.xlabel("Word")
plt.ylabel("Count")
plt.title("Top 10 Most Used Words")
plt.show()

!pip install langdetect

from langdetect import detect_langs

with open('/content/WhatsApp Chat with PE 417 Materials management(E10).txt', 'r') as f:
    text = f.read()
print(detect_langs(text))